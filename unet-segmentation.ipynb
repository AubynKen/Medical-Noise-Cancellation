{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training on online dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Module imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm # progress bar\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# custom modules\n",
    "from unet import (MaskOnlineDataset, # custom on-the-go augmentation dataset\n",
    "                   UNet) # our PyTorch U-Net model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model and cached weight imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# parameters about cached weights\n",
    "use_cached_weights = False # use models weights that we cached at checkpoint\n",
    "path_weights = \"./weights/unet-model_7000.pkl\" # path to cached weights\n",
    "previous_iter_count = 7000 # number of iterations we trained the model for before launching this notebook\n",
    "\n",
    "model = None\n",
    "if use_cached_weights:\n",
    "    # load pretrained model with pickle\n",
    "    with open(path_weights, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "else:\n",
    "    # create new model\n",
    "    model = UNet(in_channels=1, out_channels=1)\n",
    "    # use double precision\n",
    "    model.double()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# parameters used in training\n",
    "n_images = 2000 # number of images per epoch\n",
    "\n",
    "# learning rate\n",
    "# lr = 0.00001 # iter 7001 to 10000, excluding base image 7, 8, 9 for better capturing low contrast stents\n",
    "# lr = 0.00005 # iter 3001 to 7000\n",
    "# lr = 0.001 # iter 501 to 3000\n",
    "# lr = 0.005 # iter 1 to 500\n",
    "\n",
    "# custom image dataset class with on-the-go augmentation\n",
    "dataset = MaskOnlineDataset(n_images=n_images, base_image_path=\"data/dataset/base_png\")\n",
    "# pytorch dataset object\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean square error for avoiding the model to over-whiten the output image when the stent sizes are small\n",
    "criterion = CrossEntropyLoss\n",
    "optimizer = AdamW(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prediction with current weights of the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the losses for analysis\n",
    "losses = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# forward + backward + optimize\u001B[39;00m\n\u001B[1;32m      8\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(inputs)\n\u001B[0;32m----> 9\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     11\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/miniforge3/envs/forge/lib/python3.10/site-packages/torch/nn/modules/loss.py:1158\u001B[0m, in \u001B[0;36mCrossEntropyLoss.__init__\u001B[0;34m(self, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   1156\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, weight: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, size_average\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, ignore_index: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[1;32m   1157\u001B[0m              reduce\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, reduction: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m, label_smoothing: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1158\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mCrossEntropyLoss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize_average\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1159\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mignore_index \u001B[38;5;241m=\u001B[39m ignore_index\n\u001B[1;32m   1160\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_smoothing \u001B[38;5;241m=\u001B[39m label_smoothing\n",
      "File \u001B[0;32m~/miniforge3/envs/forge/lib/python3.10/site-packages/torch/nn/modules/loss.py:25\u001B[0m, in \u001B[0;36m_WeightedLoss.__init__\u001B[0;34m(self, weight, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, weight: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, size_average\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, reduce\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, reduction: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 25\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_WeightedLoss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msize_average\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregister_buffer(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m'\u001B[39m, weight)\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight: Optional[Tensor]\n",
      "File \u001B[0;32m~/miniforge3/envs/forge/lib/python3.10/site-packages/torch/nn/modules/loss.py:18\u001B[0m, in \u001B[0;36m_Loss.__init__\u001B[0;34m(self, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28msuper\u001B[39m(_Loss, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 18\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlegacy_get_string\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize_average\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction \u001B[38;5;241m=\u001B[39m reduction\n",
      "File \u001B[0;32m~/miniforge3/envs/forge/lib/python3.10/site-packages/torch/nn/_reduction.py:35\u001B[0m, in \u001B[0;36mlegacy_get_string\u001B[0;34m(size_average, reduce, emit_warning)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     33\u001B[0m     reduce \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mand\u001B[39;00m reduce:\n\u001B[1;32m     36\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m reduce:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for i, data in enumerate(tqdm(data_loader)):\n",
    "    # get the inputs\n",
    "    inputs, targets = data\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print statistics\n",
    "    losses.append(loss.item())\n",
    "    if i % 10 == 0:\n",
    "        print('Step [{}/{}], Loss: {:.10f}'.format(i+1, len(data_loader), loss.item()))\n",
    "    if i < 200 and i % 20 == 0 or i % 10 == 0:\n",
    "        print(\"Original image:\")\n",
    "        plt.figure()\n",
    "        plt.imshow(inputs.detach().numpy()[0][94:-94, 94:-94], cmap=\"gray\")\n",
    "        plt.show()\n",
    "        print(\"Predicted image:\")\n",
    "        plt.figure()\n",
    "        plt.imshow(outputs.detach().numpy()[0], cmap=\"gray\")\n",
    "        plt.show()\n",
    "        print(\"Ground truth:\")\n",
    "        plt.figure()\n",
    "        plt.imshow(targets.detach().numpy()[0], cmap=\"gray\")\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the log loss\n",
    "plt.plot(np.log(losses))\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Log MES Loss\")\n",
    "plt.show()\n",
    "\n",
    "# plot the loss\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"MES Loss\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # save the model\n",
    "# torch.save(model.state_dict(), f\"./weights/unet-weights_{previous_iter_count + n_images}.pt\")\n",
    "#\n",
    "# # use pickle to save the model\n",
    "# with open(f\"./weights/unet-model_{previous_iter_count + n_images}.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(model, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # save the losses\n",
    "# with open(f\"./weights/unet-losses-{previous_iter_count + n_images}.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(losses, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}